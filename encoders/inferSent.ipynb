{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  146M  100  146M    0     0  24.4M      0  0:00:06  0:00:06 --:--:-- 33.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0   315    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0   353    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
      "100 2075M  100 2075M    0     0  4968k      0  0:07:07  0:07:07 --:--:-- 4894k:21  0:22:12 2414k   0  0:16:40  0:00:27  0:16:13 4397k00  0:00:41  0:10:19 5249k  0  3674k      0  0:09:38  0:00:53  0:08:45 5245k:09:11  0:01:00  0:08:11 5244k0:06:42 5223k0     0  4493k      0  0:07:53  0:01:55  0:05:58 5239k 4515k      0  0:07:50  0:01:59  0:05:51 5148k:14 4786k4735k      0  0:07:28  0:03:35  0:03:53 5228k07:28  0:03:36  0:03:52 5227k9k      0  0:07:26  0:03:46  0:03:40 5225k 0:07:23  0:04:04  0:03:19 5256k0:04:19  0:03:01 5248k 0     0  4833k      0  0:07:19  0:04:26  0:02:53 5264k  0:07:16  0:04:54  0:02:22 5227k4876k      0  0:07:15  0:04:57  0:02:18 5228kk      0  0:07:14  0:05:09  0:02:05 5174k4894k      0  0:07:14  0:05:22  0:01:52 5055k      0  0:07:13  0:05:31  0:01:42 5433k  0     0  4928k      0  0:07:11  0:05:52  0:01:19 5256k      0  0:07:10  0:06:05  0:01:05 5248k6:06  0:01:04 5241k 0  0:07:10  0:06:07  0:01:03 5235k  0:06:21  0:00:48 5241k60k      0  0:07:08  0:06:33  0:00:35 5242kk      0  0:07:08  0:06:38  0:00:30 4827k4959k      0  0:07:08  0:06:43  0:00:25 5015k0:09 5158k\n",
      "Archive:  GloVe/glove.840B.300d.zip\n",
      "  inflating: GloVe/glove.840B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "! mkdir encoder\n",
    "! curl -Lo encoder/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl\n",
    "  \n",
    "! mkdir GloVe\n",
    "! curl -Lo GloVe/glove.840B.300d.zip http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "! unzip GloVe/glove.840B.300d.zip -d GloVe/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I ate dinner.\", \n",
    "       \"We had a three-course meal.\", \n",
    "       \"Brad came to dinner with us.\",\n",
    "       \"He loves fish tacos.\",\n",
    "       \"In the end, we all felt like we ate too much.\",\n",
    "       \"We all agreed; it was a magnificent evening.\"]\n",
    "import numpy as np\n",
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import InferSent\n",
    "import torch\n",
    "\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "W2V_PATH = './GloVe/glove.840B.300d.txt'\n",
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36(/36) words with w2v vectors\n",
      "Vocab size : 36\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(sentences, tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/varunsatheesh/capstone/encoders/models.py:207: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sentences = np.array(sentences)[idx_sort]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.02459561,  0.04943121, -0.15705208, ...,  0.07534432,\n",
       "       -0.039418  ,  0.05388856], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"I had pizza and pasta\"\n",
    "query_vec = model.encode(query)[0]\n",
    "query_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence =  I ate dinner. ; similarity =  0.686888\n",
      "Sentence =  We had a three-course meal. ; similarity =  0.50432706\n",
      "Sentence =  Brad came to dinner with us. ; similarity =  0.55740434\n",
      "Sentence =  He loves fish tacos. ; similarity =  0.59071404\n",
      "Sentence =  In the end, we all felt like we ate too much. ; similarity =  0.57681185\n",
      "Sentence =  We all agreed; it was a magnificent evening. ; similarity =  0.50499654\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "for sent in sentences:\n",
    "  sim = cosine(query_vec, model.encode([sent])[0])\n",
    "  print(\"Sentence = \", sent, \"; similarity = \", sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
